{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code required by local PC\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Determine the parent directory\n",
    "# Use os.path.abspath and os.path.join to get the absolute path to the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "\n",
    "# Add the parent directory to sys.path\n",
    "# This allows importing modules from the parent directory\n",
    "sys.path.append(parent_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_prepare_data(file_path):\n",
    "    # Load the data\n",
    "    data = pd.read_parquet(file_path, columns=['text', 'text_b', 'label'])\n",
    "    \n",
    "    # Cast label column to integer\n",
    "    data['label'] = data['label'].astype(int)\n",
    "    \n",
    "    # Data shuffling\n",
    "    data = data.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Initial number of rows: 3030\n",
      "Train set: Number of rows after removing nulls and duplicates: 2909\n",
      "Test set: Initial number of rows: 808\n",
      "Test set: Number of rows after removing nulls and duplicates: 776\n"
     ]
    }
   ],
   "source": [
    "from src.data_cleaning import clearing\n",
    "# Call the clearing function to execute the dataset cleaning process\n",
    "clearing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the parent directory of the current working directory\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare cleaned training data\n",
    "clean_train_path = os.path.join(parent_dir, 'data', 'clean_train.parquet')\n",
    "train_data = load_and_prepare_data(clean_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "train_data, val_data = train_test_split(train_data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the cleaned training and validation DataFrames to new .parquet files\n",
    "train_data.to_parquet(os.path.join(parent_dir, 'data', 'clean_train.parquet'))\n",
    "val_data.to_parquet(os.path.join(parent_dir, 'data', 'clean_val.parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare cleaned test data\n",
    "clean_test_path = os.path.join(parent_dir, 'data', 'clean_test.parquet')\n",
    "test_data = load_and_prepare_data(clean_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert training and validation sets to dictionary lists\n",
    "train_list = train_data.to_dict(orient='records')\n",
    "val_list = val_data.to_dict(orient='records')\n",
    "# Convert test set to dictionary list\n",
    "test_list = test_data.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2327\n",
      "582\n",
      "776\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Result output\n",
    "print(len(train_list))\n",
    "print(len(val_list))\n",
    "print(len(test_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
